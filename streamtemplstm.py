# -*- coding: utf-8 -*-
"""streamTempLSTM.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KNPE0FVuSmfX6XdSXYz5MXghLr2qMw_x
"""

import os
from typing import Tuple

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import TensorDataset, DataLoader
import tqdm

#Reshaping 2D Array into 3D array for LSTM model
def reshape_data(
    x: np.ndarray,
    y: np.ndarray,
    seq_length: int
) -> Tuple[np.ndarray, np.ndarray]:
    if y.ndim == 1:
        y = y.reshape(-1, 1)

    n_samples, n_features = x.shape
    n_sequences = n_samples - seq_length + 1

    x_seq = np.zeros((n_sequences, seq_length, n_features), dtype=x.dtype)
    y_seq = np.zeros((n_sequences, 1), dtype=y.dtype)

    for i in range(n_sequences):
        x_seq[i] = x[i : i + seq_length]
        y_seq[i] = y[i + seq_length - 1]

    return x_seq, y_seq

#Calculating rmse for the loss function
def calc_rmse(obs: np.ndarray, sim: np.ndarray) -> float:
    """Calculate Root Mean Squared Error."""
    mask = (obs >= 0) & ~np.isnan(obs)
    o, s = obs[mask], sim[mask]
    return float(np.sqrt(np.mean((s - o) ** 2)))

#Plottnig result
def plot_results(
    date_range,
    observations: np.ndarray,
    predictions: np.ndarray,
    basin: int,
    nse: float
):
    """Plot observed vs predicted time series with RMSE annotation."""
    sns.set_style("whitegrid")
    fig, ax = plt.subplots(figsize=(16, 6))
    ax.plot(date_range, observations, label="Observation", linewidth=1, linestyle='-', marker='o', markersize=2)
    ax.plot(date_range, predictions, label="Prediction", linewidth=1, linestyle='--', marker='x', markersize=2)
    ax.legend(fontsize='large')
    ax.set_title(f"Basin {basin} - Test set NSE: {nse:.3f}", fontsize=16)
    ax.set_xlabel("", fontsize=14) # Removed x-axis label
    ax.set_ylabel("Temperature (°C)", fontsize=14)
    ax.tick_params(axis='x', rotation=45)
    ax.tick_params(axis='both', which='major', labelsize=12)
    ax.grid(True, which='both', linestyle='--', linewidth=0.5)
    # Format x-axis to show only month and day
    import matplotlib.dates as mdates
    ax.xaxis.set_major_formatter(mdates.DateFormatter('%m-%d'))
    plt.tight_layout()
    plt.show()

#LSTM model
class LSTMModel(nn.Module):
    """
    Single-layer LSTM regressor with optional static features.
    """
    def __init__(
        self,
        input_size: int,
        hidden_size: int,
        num_layers: int = 1,
        dropout: float = 0.0,
        static_size: int = 0,
    ):
        super().__init__()
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        self.static_size = static_size
        lstm_input_size = input_size + static_size
        self.lstm = nn.LSTM(
            input_size=lstm_input_size,
            hidden_size=hidden_size,
            num_layers=num_layers,
            batch_first=True,
            dropout=dropout if num_layers > 1 else 0.0
        )
        self.dropout = nn.Dropout(p=dropout)
        self.fc = nn.Linear(hidden_size, 1)

    def forward(self, x: torch.Tensor, static: torch.Tensor = None) -> torch.Tensor:
        if self.static_size > 0:
            if static is None:
                raise ValueError("static_size>0 but no static tensor provided")
            seq_len = x.size(1)
            static_rep = static.unsqueeze(1).repeat(1, seq_len, 1)
            x = torch.cat([x, static_rep], dim=-1)

        _, (h_n, _) = self.lstm(x)
        last_hidden = h_n[-1]
        out = self.fc(self.dropout(last_hidden))
        return out

#train epoch function
def train_epoch(
    model: nn.Module,
    optimizer: optim.Optimizer,
    loader: DataLoader,
    loss_func,
    epoch: int,
    device: torch.device
):
    model.train()
    pbar = tqdm.tqdm(loader, desc=f"Epoch {epoch}", leave=False)
    for xs, ys in pbar:
        xs, ys = xs.to(device), ys.to(device)
        optimizer.zero_grad()
        y_hat = model(xs)
        loss = loss_func(y_hat, ys)
        loss.backward()
        optimizer.step()
        pbar.set_postfix_str(f"Loss: {loss.item():.4f}")

#Evaluating model
def eval_model(
    model: nn.Module,
    loader: DataLoader,
    device: torch.device
) -> Tuple[torch.Tensor, torch.Tensor]:
    model.eval()
    obs_list, pred_list = [], []
    with torch.no_grad():
        for xs, ys in loader:
            xs = xs.to(device)
            y_hat = model(xs)
            obs_list.append(ys)
            pred_list.append(y_hat.cpu())
    obs = torch.cat(obs_list).cpu()
    preds = torch.cat(pred_list).cpu()
    return obs, preds

#Training model
# Settings
DEVICE       = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
DATA_DIR     = './'  # path to your CSV files (Only works for Google Colab IDK for VSCODe)
BATCH_SIZE   = 100
SEQ_LEN      = 10
N_EPOCHS     = 50
HIDDEN_SIZE  = 50
DROPOUT_RATE = 0.1
LEARNING_RATE= 0.001
#START_DATE   = '2021-04-16' Don;t know the start date
FREQ         = 'D'
BASIN        = 1573

# 1) Load preprocessed CSVs
X_train_df = pd.read_csv(os.path.join(DATA_DIR, 'pretrain_site_input_X_train.csv'))
X_test_df  = pd.read_csv(os.path.join(DATA_DIR, 'pretrain_site_input_X_test.csv'))
y_train_df = pd.read_csv(os.path.join(DATA_DIR, 'pretrain_site_input_Y_train.csv'))
y_test_df  = pd.read_csv(os.path.join(DATA_DIR, 'pretrain_site_input_Y_test.csv'))

# 2) Convert to NumPy
X_train = X_train_df.values
y_train = y_train_df.values.squeeze()
X_test  = X_test_df.values
y_test  = y_test_df.values.squeeze()

# 3) Build sequences
X_train_seq, y_train_seq = reshape_data(X_train, y_train, SEQ_LEN)
X_test_seq,  y_test_seq  = reshape_data(X_test,  y_test,  SEQ_LEN)

# 4) Standardize targets
from sklearn.preprocessing import StandardScaler
y_scaler = StandardScaler()
y_train_seq = y_scaler.fit_transform(y_train_seq)
y_test_seq  = y_scaler.transform(y_test_seq)

# 5) DataLoaders
train_ds = TensorDataset(
    torch.from_numpy(X_train_seq).float(),
    torch.from_numpy(y_train_seq).float()
)
test_ds  = TensorDataset(
    torch.from_numpy(X_test_seq).float(),
    torch.from_numpy(y_test_seq).float()
)
train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=False)
test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False)

# 6) Model, optimizer, loss
model     = LSTMModel(input_size=X_train_seq.shape[2], hidden_size=HIDDEN_SIZE, dropout=DROPOUT_RATE).to(DEVICE)
optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)
loss_func = nn.MSELoss()

# 7) Training loop
for epoch in range(1, N_EPOCHS+1):
    train_epoch(model, optimizer, train_loader, loss_func, epoch, DEVICE)
    obs, preds = eval_model(model, test_loader, DEVICE)
    preds_rescaled = y_scaler.inverse_transform(preds.numpy())
    obs_rescaled   = y_scaler.inverse_transform(obs.numpy())
    nse_val = calc_rmse(obs_rescaled.squeeze(), preds_rescaled.squeeze())
    tqdm.tqdm.write(f"Epoch {epoch:02d} — Test RMSE: {nse_val:.3f}")

# 8) Plot results
# generate a date range for plotting
date_range = pd.date_range(start=START_DATE, periods=len(obs_rescaled), freq=FREQ)
plot_results(date_range, obs_rescaled.squeeze(), preds_rescaled.squeeze(), BASIN, nse_val)

def main():

    # 1) Load your normalized forecast CSVs
    fc_X_df = pd.read_csv(os.path.join(DATA_DIR, 'forecast_site_input_X.csv'))
    fc_Y_df = pd.read_csv(os.path.join(DATA_DIR, 'forecast_site_input_Y.csv'))

    # 2) Convert to NumPy arrays
    fc_X = fc_X_df.values
    fc_Y = fc_Y_df.values.squeeze()

    # 3) Build sliding windows
    fc_X_seq, fc_Y_seq = reshape_data(fc_X, fc_Y.reshape(-1,1), SEQ_LEN)

    # 4) DataLoader
    fc_ds     = TensorDataset(
        torch.from_numpy(fc_X_seq).float(),
        torch.from_numpy(fc_Y_seq).float()
    )
    fc_loader = DataLoader(fc_ds, batch_size=BATCH_SIZE, shuffle=False)

    # 5) Inference
    model.eval()
    pred_norm, obs_norm = [], []
    with torch.no_grad():
        for xs, ys in fc_loader:
            xs = xs.to(DEVICE)
            yhat = model(xs)
            pred_norm.append(yhat.cpu())
            obs_norm.append(ys)
    pred_norm = torch.cat(pred_norm).numpy().squeeze()
    obs_norm  = torch.cat(obs_norm).numpy().squeeze()

    # 6) Inverse‐scale
    preds = y_scaler.inverse_transform(pred_norm.reshape(-1,1)).squeeze()
    obs   = y_scaler.inverse_transform(obs_norm.reshape(-1,1)).squeeze()

    # 7) Metrics & plot
    rmse_fc = calc_rmse(obs, preds)
    print(f"7-day Forecast RMSE: {rmse_fc:.3f}")

    last_test_date = date_range[-1]
    forecast_dates = pd.date_range(
        start=last_test_date + pd.Timedelta(days=1),
        periods=len(preds),
        freq=FREQ
    )
    plot_results(forecast_dates, obs, preds, BASIN, rmse_fc)


if __name__ == "__main__":
    main()